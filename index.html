<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <title>Mohamed Shawky Sabae</title>
    <meta
      name="description"
      content="Online Portofolio for Mohamed Shawky Sabae"
    />
    <meta name="author" content="Mohamed Shawky" />

    <!-- Mobile-friendly -->
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <!-- Bootstrap CSS -->
    <link
      rel="stylesheet"
      href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css"
      integrity="sha384-JcKb8q3iqJ61gNV9KGb8thSsNjpSL0n8PARn9HuZOnIxN0hoP+VmmDGMN5t9UJ0Z"
      crossorigin="anonymous"
    />

    <!-- Minimalist CSS -->
    <link rel="stylesheet" href="assets/css/minimalist.css" />

    <!-- FontAwesome -->
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"
      integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog=="
      crossorigin="anonymous"
    />

    <!-- Favicon -->
    <link rel="icon" type="image/png" href="assets/images/favicon.ico" />
  </head>
  <body>
    <!-- User info -->
    <header>
      <div class="container">
        <div class="row justify-content-lg-center">
          <div class="col-lg-2 text-center">
            <img
              src="assets/images/profile.jpg"
              class="user-image rounded-circle"
              alt="Mohamed Shawky Sabae"
            />
          </div>
          <div class="col-lg-7">
            <h2>Mohamed Shawky Sabae</h2>
            <p class="text-justify">
              Computer Vision Engineer at <b>Rembrand</b>.
              Teaching Assistant in Computer Engineering at <b>Cairo University</b>.
              Working at the intersection of computer vision and computer graphics,
              with research interests in 3D computer vision, inverse rendering,
              differentiable rendering, and implicit neural representations.
            </p>
            <ul class="list-inline text-lg-right social-icons">
              <li class="list-inline-item">
                <a
                  href="https://www.linkedin.com/in/mohamed-shawky/"
                  target="_blank"
                  ><i class="fab fa-linkedin-in"></i
                ></a>
              </li>
              <li class="list-inline-item">
                <a href="https://github.com/DarkGeekMS" target="_blank"
                  ><i class="fab fa-github"></i
                ></a>
              </li>
              <li class="list-inline-item">
                <a
                  href="https://scholar.google.com/citations?user=OA_UwCIAAAAJ&hl=en"
                  target="_blank"
                  ><i class="fa fa-graduation-cap"></i
                ></a>
              </li>
              <li class="list-inline-item">
                <a href="mailto:mohamedshawky911@gmail.com" target="_blank"
                  ><i class="fas fa-at"></i
                ></a>
              </li>
              <li class="list-inline-item">
                <a
                  href="https://drive.google.com/file/d/1952RX-jRaPZokEK95Da5Um0_Y24G5n7D/view?usp=sharing"
                  target="_blank"
                  ><i class="fab fa-google-drive"></i
                ></a>
              </li>
            </ul>
          </div>
        </div>
      </div>
    </header>
    <!-- Content -->
    <section>
      <!-- ./content-switch -->
      <div class="d-flex justify-content-center">
        <div
          class="list-group list-group-horizontal-md"
          id="content-tabs"
          role="tablist"
        >
          <a
            class="list-group-item small text-uppercase active"
            id="list-experience-list"
            data-toggle="list"
            href="#experience"
            role="tab"
            >Experience</a
          >
          <a
            class="list-group-item small text-uppercase"
            id="list-education-list"
            data-toggle="list"
            href="#education"
            role="tab"
            >Education</a
          >
          <a
            class="list-group-item small text-uppercase"
            id="list-publications-list"
            data-toggle="list"
            href="#publications"
            role="tab"
            >Publications</a
          >
          <a
            class="list-group-item small text-uppercase"
            id="list-projects-list"
            data-toggle="list"
            href="#projects"
            role="tab"
            >Projects</a
          >
        </div>
      </div>
      <!-- ./content-switch -->
      <!-- ./content-body -->
      <div class="container pt-5 tab-content">
        <!-- ./experience-panel-->
        <div class="tab-pane fade show active" id="experience" role="tabpanel">
          <div class="row justify-content-lg-center">
            <div class="col-lg">
              <!-- Timeline -->
              <div class="timeline-container">
                <div class="timeline-block timeline-block-right">
                  <div class="marker"></div>
                  <div class="timeline-content">
                    <h3 class="timeline-h3">Computer Vision Engineer</h3>
                    <span class="timeline-span">Rembrand</span>
                    <p class="text-muted small mb-3">March 2023 - Present</p>
                    <p class="timeline-p text-justify">
                      Developing computer vision and generative AI solutions
                      for virtual product placement. Working on inverse rendering
                      methods for material and light decomposition from RGB images.
                      Working on 3D reconstruction pipelines to recover camera
                      parameters and scene geometry from videos.
                    </p>
                  </div>
                </div>

                <div class="timeline-block timeline-block-left">
                  <div class="timeline-content">
                    <h3 class="timeline-h3">Teaching Assistant</h3>
                    <span class="timeline-span"
                      >Faculty of Engineering, Cairo University</span
                    >
                    <p class="text-muted small mb-3">December 2022 - Present</p>
                    <p class="timeline-p text-justify">
                      Handling course recitations and labs at Computer
                      Engineering department.
                      <b>Courses:</b> Computer Vision - Computer Graphics -
                      Machine Learning - Neural Networks - Cognitive Robotics.
                    </p>
                  </div>
                  <div class="marker"></div>
                </div>

                <div class="timeline-block timeline-block-right">
                  <div class="marker"></div>
                  <div class="timeline-content">
                    <h3 class="timeline-h3">Computer Vision Engineer</h3>
                    <span class="timeline-span">Anovate.ai</span>
                    <p class="text-muted small mb-3">
                      August 2021 - February 2023
                    </p>
                    <p class="timeline-p text-justify">
                      Worked on deep learning applications for 3D computer
                      vision, including 3D scene understanding and 3D object
                      reconstruction. Developed a pipeline for 3D mesh
                      processing and wireframe parsing. Worked on instance
                      segmentation for satellite imagery. Deployed high
                      performance deep learning models in production using
                      tools, including NVIDIA Triton Inference Server. Managed
                      machine learning projects, along with communication with
                      their clients.
                    </p>
                  </div>
                </div>

                <div class="timeline-block timeline-block-left">
                  <div class="timeline-content">
                    <h3 class="timeline-h3">Student Developer at RoboComp</h3>
                    <span class="timeline-span"
                      >Google Summer of Code 2020</span
                    >
                    <p class="text-muted small mb-3">May 2020 - August 2020</p>
                    <p class="timeline-p text-justify">
                      <b>Project title :</b>
                      <a
                        href="https://summerofcode.withgoogle.com/projects/#5216435518832640"
                        >DNNs for precise manipulation of household objects</a
                      >. Implemented and optimized segmentation-driven 6D pose
                      estimation neural network architecture. Used CoppeliaSim
                      simulator to test pose estimation performance and augment
                      training data. Integrated and tested pose estimation
                      components with the new software architecture (based on
                      DSR (Deep State Representation) and implemented using CRDT
                      and RTPS) for precise manipulation of household objects.
                    </p>
                  </div>
                  <div class="marker"></div>
                </div>

                <div class="timeline-block timeline-block-right">
                  <div class="marker"></div>
                  <div class="timeline-content">
                    <h3 class="timeline-h3">Deep Learning Research Intern</h3>
                    <span class="timeline-span">Valeo</span>
                    <p class="text-muted small mb-3">
                      July 2019 - September 2019
                    </p>
                    <p class="timeline-p text-justify">
                      Studied the effect of neural style transfer in modeling
                      the real sensor noise, experimented with offline style
                      transfer methods, including single, multiple and arbitrary
                      style transfer. Applied generative adversarial networks
                      (GANs) like CycleGAN, and neural style transfer on domain
                      translation of LiDAR data from simulated (CARLA) to real
                      (KITTI). Improved the performance of YOLO object detection
                      on LiDAR data by 6%, by augmenting using domain translated
                      data. Built an end-to-end architecture, where YOLO object
                      detector loss in combined with CycleGAN to improve
                      training.
                    </p>
                  </div>
                </div>
              </div>
              <!-- ./timeline -->
            </div>
          </div>
        </div>
        <!-- ./education-panel-->
        <div class="tab-pane fade show" id="education" role="tabpanel">
          <div class="row justify-content-lg-center">
            <div class="col-lg">
              <!-- Timeline -->
              <div class="timeline-container">
                <div class="timeline-block timeline-block-right">
                  <div class="marker"></div>
                  <div class="timeline-content">
                    <h3 class="timeline-h3">
                      Master of Science - Computer Engineering
                    </h3>
                    <span class="timeline-span"
                      >Faculty of Engineering, Cairo University</span
                    >
                    <p class="text-muted small mb-3">October 2022 - January 2025</p>
                    <p class="timeline-p text-justify">
                      <b>GPA:</b> 3.97.
                      <b>Thesis:</b> Neural Implicit Camera and Geometry Representations
                      for Multiview 3D Reconstruction Without Camera Parameters.
                    </p>
                  </div>
                </div>

                <div class="timeline-block timeline-block-left">
                  <div class="timeline-content">
                    <h3 class="timeline-h3">
                      Bachelor of Science - Computer Engineering
                    </h3>
                    <span class="timeline-span"
                      >Faculty of Engineering, Cairo University</span
                    >
                    <p class="text-muted small mb-3">
                      September 2016 - May 2021
                    </p>
                    <p class="timeline-p text-justify">
                      <b>Grade:</b> Distinction with Honors.
                      <b>Cumulative Percentage:</b> 91%. <b>GPA:</b> 4.00.
                      <b>Rank:</b> 4th (out of 71). <b>Graduation Thesis:</b>
                      Face Generation from Text using StyleGAN2.
                    </p>
                  </div>
                  <div class="marker"></div>
                </div>
              </div>
              <!-- ./timeline -->
            </div>
          </div>
        </div>
        <!-- ./publications-panel-->
        <div class="tab-pane fade show" id="publications" role="tabpanel">
          <div class="row justify-content-lg-center">
            <!-- ./project-1 -->
            <div class="col-lg-8 pb-3">
              <div class="card">
                <div class="card-body">
                  <h4 class="card-title">
                    NoPose-NeuS: Jointly Optimizing Camera Poses with Neural
                    Implicit Surfaces for Multi-view Reconstruction
                  </h4>
                  <h6 class="card-text">
                    NeurIPS 2023 UniReps Workshop · Dec 15, 2023
                  </h6>
                  <p class="card-text text-justify">
                    <b>Abstract:</b> Learning neural implicit surfaces from
                    volume rendering has become popular for multi-view
                    reconstruction. Neural surface reconstruction approaches can
                    recover complex 3D geometry that are difficult for classical
                    Multi-view Stereo (MVS) approaches, such as non-Lambertian
                    surfaces and thin structures. However, one key assumption
                    for these methods is knowing accurate camera parameters for
                    the input multi-view images, which are not always available.
                    In this paper, we present NoPose-NeuS, a neural implicit
                    surface reconstruction method that extends NeuS to jointly
                    optimize camera poses with the geometry and color networks.
                    We encode the camera poses as a multi-layer perceptron (MLP)
                    and introduce two additional losses, which are multi-view
                    feature consistency and rendered depth losses, to constrain
                    the learned geometry for better estimated camera poses and
                    scene surfaces. Extensive experiments on the DTU dataset
                    show that the proposed method can estimate relatively
                    accurate camera poses, while maintaining a high surface
                    reconstruction quality with 0.89 mean Chamfer distance.
                  </p>
                  <ul class="list-inline social-icons">
                    <li class="list-inline-item">
                      <a href="https://openreview.net/forum?id=TOp8uT3DZ9"
                        ><i class="fas fa-link"></i
                      ></a>
                    </li>
                  </ul>
                </div>
              </div>
            </div>
            <!-- Force next columns to break to new line -->
            <div class="w-100"></div>
            <!-- ./project-2 -->
            <div class="col-lg-8 pb-3">
              <div class="card">
                <div class="card-body">
                  <h4 class="card-title">
                    StyleT2F: Generating Human Faces from Textual Description
                    Using StyleGAN2
                  </h4>
                  <h6 class="card-text">arXiv preprint · Apr 17, 2022</h6>
                  <p class="card-text text-justify">
                    <b>Abstract:</b> AI-driven image generation has improved
                    significantly in recent years. Generative adversarial
                    networks (GANs), like StyleGAN, are able to generate
                    high-quality realistic data and have artistic control over
                    the output, as well. In this work, we present StyleT2F, a
                    method of controlling the output of StyleGAN2 using text, in
                    order to be able to generate a detailed human face from
                    textual description. We utilize StyleGAN's latent space to
                    manipulate different facial features and conditionally
                    sample the required latent code, which embeds the facial
                    features mentioned in the input text. Our method proves to
                    capture the required features correctly and shows
                    consistency between the input text and the output images.
                    Moreover, our method guarantees disentanglement on
                    manipulating a wide range of facial features that
                    sufficiently describes a human face.
                  </p>
                  <ul class="list-inline social-icons">
                    <li class="list-inline-item">
                      <a href="https://arxiv.org/abs/2204.07924"
                        ><i class="fas fa-link"></i
                      ></a>
                    </li>
                  </ul>
                </div>
              </div>
            </div>
            <!-- Force next columns to break to new line -->
            <div class="w-100"></div>
            <!-- ./project-3 -->
            <div class="col-lg-8 pb-3">
              <div class="card">
                <div class="card-body">
                  <h4 class="card-title">
                    Unsupervised Neural Sensor Models for Synthetic LiDAR Data
                    Augmentation
                  </h4>
                  <h6 class="card-text">
                    NeurIPS 2019 Machine Learning for Autonomous Driving
                    Workshop · Dec 1, 2019
                  </h6>
                  <p class="card-text text-justify">
                    <b>Abstract:</b> Data scarcity is a bottleneck to machine
                    learning-based perception modules, usually tackled by
                    augmenting real data with synthetic data from simulators.
                    Realistic models of the vehicle perception sensors are hard
                    to formulate in closed form, and at the same time, they
                    require the existence of paired data to be learned. In this
                    work, we propose two unsupervised neural sensor models based
                    on unpaired domain translations with CycleGANs and Neural
                    Style Transfer techniques. We employ CARLA as the simulation
                    environment to obtain simulated LiDAR point clouds, together
                    with their annotations for data augmentation, and we use
                    KITTI dataset as the real LiDAR dataset from which we learn
                    the realistic sensor model mapping. Moreover, we provide a
                    framework for data augmentation and evaluation of the
                    developed sensor models, through extrinsic object detection
                    task evaluation using YOLO network adapted to provide
                    oriented bounding boxes for LiDAR Bird-eye-View projected
                    point clouds. Evaluation is performed on unseen real LiDAR
                    frames from KITTI dataset, with different amounts of
                    simulated data augmentation using the two proposed
                    approaches, showing improvement of 6% mAP for the object
                    detection task, in favor of the augmenting LiDAR point
                    clouds adapted with the proposed neural sensor models over
                    the raw simulated LiDAR.
                  </p>
                  <ul class="list-inline social-icons">
                    <li class="list-inline-item">
                      <a href="https://arxiv.org/abs/1911.10575"
                        ><i class="fas fa-link"></i
                      ></a>
                    </li>
                  </ul>
                </div>
              </div>
            </div>
            <!-- Force next columns to break to new line -->
            <div class="w-100"></div>
          </div>
        </div>
        <!-- ./projects-panel-->
        <div class="tab-pane fade show" id="projects" role="tabpanel">
          <!-- TODO: Projects cards? Dunno. -->
          <div class="row justify-content-lg-center">
            <!-- ./project-1 -->
            <div class="col-lg-8 pb-3">
              <div class="card">
                <div class="card-body">
                  <h4 class="card-title">
                    Generative Data Augmentation for Semantic Segmentation
                  </h4>
                  <p class="card-text text-justify">
                    A research project for enhancing semantic segmentation
                    methods using synthetic data from generative image-to-image
                    translation in an end-to-end approach. End-to-end training
                    workflow of Pix2Pix image translation guided by UNet
                    segmentation.
                  </p>
                  <ul class="list-inline social-icons">
                    <li class="list-inline-item">
                      <a
                        href="https://github.com/DarkGeekMS/generative-segmentation"
                        target="_blank"
                        ><i class="fab fa-github"></i
                      ></a>
                    </li>
                  </ul>
                </div>
              </div>
            </div>
            <!-- Force next columns to break to new line -->
            <div class="w-100"></div>
            <!-- ./project-2 -->
            <div class="col-lg-8 pb-3">
              <div class="card">
                <div class="card-body">
                  <h4 class="card-title">
                    Neural Malware Signature Generation
                  </h4>
                  <p class="card-text text-justify">
                    A research project for generating malware signatures using
                    end-to-end neural networks. Training AutoEncoders on
                    image-encoded malwares to generate latent representations
                    used as signatures.
                  </p>
                  <ul class="list-inline social-icons">
                    <li class="list-inline-item">
                      <a
                        href="https://github.com/DarkGeekMS/neural-malware-signature"
                        target="_blank"
                        ><i class="fab fa-github"></i
                      ></a>
                    </li>
                  </ul>
                </div>
              </div>
            </div>
            <!-- Force next columns to break to new line -->
            <div class="w-100"></div>
            <!-- ./project-3 -->
            <div class="col-lg-8 pb-3">
              <div class="card">
                <div class="card-body">
                  <h4 class="card-title">Retratista (Graduation Project)</h4>
                  <p class="card-text text-justify">
                    A software (web application) for human face generation and
                    manipulation from speech and textual description using
                    generative adversarial networks (GANs). Designed and
                    implemented the generation of face embedding and morphing
                    using StyleGAN2.
                  </p>
                  <ul class="list-inline social-icons">
                    <li class="list-inline-item">
                      <a
                        href="https://github.com/DarkGeekMS/Retratista"
                        target="_blank"
                        ><i class="fab fa-github"></i
                      ></a>
                    </li>
                  </ul>
                </div>
              </div>
            </div>
            <!-- Force next columns to break to new line -->
            <div class="w-100"></div>
            <!-- ./project-4 -->
            <div class="col-lg-8 pb-3">
              <div class="card">
                <div class="card-body">
                  <h4 class="card-title">
                    Artistic Style Transfer Using Texture Synthesis
                  </h4>
                  <p class="card-text text-justify">
                    A python implementation of Style-Transfer via
                    Texture-Synthesis paper, which uses classical methods.
                    Implemented the main stylization loop and learning
                    algorithms.
                  </p>
                  <ul class="list-inline social-icons">
                    <li class="list-inline-item">
                      <a
                        href="https://github.com/DarkGeekMS/artistic-style-transfer-using-texture-synthesis"
                        target="_blank"
                        ><i class="fab fa-github"></i
                      ></a>
                    </li>
                  </ul>
                </div>
              </div>
            </div>
            <!-- Force next columns to break to new line -->
            <div class="w-100"></div>
            <!-- ./project-5 -->
            <div class="col-lg-8 pb-3">
              <div class="card">
                <div class="card-body">
                  <h4 class="card-title">
                    In the Middle of Nowhere (OpenGL Game)
                  </h4>
                  <p class="card-text text-justify">
                    A primitive 3D game using OpenGL with C++, created for
                    Computer Graphics Course, where I only used simple 3d models
                    and created shaders for some effects using GLSL.
                  </p>
                  <ul class="list-inline social-icons">
                    <li class="list-inline-item">
                      <a
                        href="https://github.com/DarkGeekMS/OpenGL-In-The-Middle-Of-Nowhere"
                        target="_blank"
                        ><i class="fab fa-github"></i
                      ></a>
                    </li>
                  </ul>
                </div>
              </div>
            </div>
            <!-- Force next columns to break to new line -->
            <div class="w-100"></div>
          </div>
        </div>
      </div>
    </section>
    <!-- JavaScript -->
    <script
      src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
      integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js"
      integrity="sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"
      integrity="sha384-B4gt1jrGC7Jh4AgTPSdUtOBvfO8shuf57BaghqFfPlYxofvL8/KUEfYiJOMMV+rV"
      crossorigin="anonymous"
    ></script>
  </body>
</html>
